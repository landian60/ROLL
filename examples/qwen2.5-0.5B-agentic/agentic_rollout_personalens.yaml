defaults:
  - ../config/traj_envs@_here_
  - ../config/deepspeed_zero@_here_
  - ../config/deepspeed_zero2@_here_
  - ../config/deepspeed_zero3@_here_
  - ../config/deepspeed_zero3_cpuoffload@_here_

hydra:
  run:
    dir: .
  output_subdir: null

exp_name: "agentic_pipeline_personalens"
seed: 42
logging_dir: ./output/logs
output_dir: ./output
render_save_dir: ./output/render

#track_with: wandb
#tracker_kwargs:
#  api_key:
#  project: roll-agentic
#  name: ${exp_name}_personalens
#  notes: "agentic_pipeline"
#  tags:
#    - agentic
#    - roll
#    - personalens

track_with: tensorboard
tracker_kwargs:
  log_dir: /home/liuguanming/Multimodal-Agent/roll_MInt/ROLL/examples/qwen2.5-0.5B-agentic/log

num_gpus_per_node: 1

max_steps: 1024
save_steps: 10000

rollout_batch_size: 64
sequence_length: 8192

pretrain: Qwen/Qwen2.5-0.5B-Instruct

actor_infer:
  model_args:
    disable_gradient_checkpointing: true
    dtype: bf16
  generating_args:
    max_new_tokens: 256 # single-turn response length (longer for conversation)
    top_p: 0.99
    top_k: 100
    num_beams: 1
    temperature: 0.99
    num_return_sequences: 1
  data_args:
    template: qwen2_5
  strategy_args:
    strategy_name: vllm
    strategy_config:
      gpu_memory_utilization: 0.8
      block_size: 16
      load_format: auto # should set 'auto' here, because default load_format is 'dummy'
  device_mapping: "[0]"

train_env_manager:
  format_penalty: -0.1 # personalens env format penalty
  max_env_num_per_worker: 1
  num_env_groups: 1
  # under the same group, the env config and env seed are ensured to be equal
  group_size: 1
  tags: [PersonaLens]
  num_groups_partition: [1] # If not set, all env names divide nums equally. Under the same group, the env config and env seed (prompt) are equal in each generation

# Here, you can override variables defined in the imported envs. max_tokens_per_step: 128 in custom_env.PersonaLens, here replaced by 128
max_tokens_per_step: 128

custom_envs:
  PersonaLens:
    ${custom_env.PersonaLens}
